# Introduction 

The success of soil mapping activities relies on the existence of proper data collated through detailed soil sampling protocols ensuring representative and reliable soil data collection. This publication does not intend to be an intensive compilation which cover all the intricate possibilities in soil sampling design. In turn, we show a number of different soil sampling protocols through examples, covering both the most common approaches that can be used for the design of field soil sampling and present methodologies to evaluate their accuracy and effectiveness. The last part of the manual is particularly focused in the use of conditional Latin Hypercube Sampling (cLHS), a statistical methodology developed specifically for soil sampling from a Digital Soil Mapping perspective [@minasny2006].

The manual is structured in two parts. `'Part One'` presents a methodology to evaluate the capacity of an existing soil legacy data to represent the potential soil diversity within a certain study area and determine whether it is a valid set for Digital Soil Mapping purposes.  We use the Kullback-Leibler divergence (KL) measurement to quantify the difference between the probability distributions of covariate values in the legacy samples set and in the whole area and determine how much information is lost when the sample set is used to approximate the diversity in the existing environmental conditions in the whole area.

In `'Part Two'` we present several methods for creating soil sampling designs. We start with the determination of the minimum sample size required for describing most of the environmental diversity in the area, to the creation of sampling designs. We present examples of various sampling methods, ranging from traditional grid-based approaches to advanced statistical sampling strategies. We include methods for systematic, random and stratified sampling, evaluating their strengths and weaknesses in the context of DSM.


## Training material

The manual exercises are written in the statistical environment **R** and run in the integrated development environment (IDE) **RStudio** for simplicity. Some scripts include modifications of the work from[@Malone](https://bitbucket.org/brendo1001/clhc_sampling/src/master/), and [@Brus2022](https://dickbrus.github.io/SpatialSamplingwithR/), which can be found at their respective repositories.

The training material for this book is located in the [Sampling-Design-TM GitHub repository](https://github.com/FAO-GSP/Sampling-Design-TM). To download the input files and R scripts, clone the repository or click on [this link](https://github.com/FAO-GSP/Sampling-Design-TM/archive/refs/heads/main.zip), save the ZIP file, and extract its content in a folder, preferable located close to the root of your system, such as ```"C:/GIT/"```.  Raster data can be also downloaded from the Google Earth repository of FAO-GPS (digital-soil-mapping-gsp-fao). Script 2 in the Annexes can be used in the code editor at Google Earth Engine to download the necessary environmental covariates.

We have used a common structure for file paths in the exercises. By default, the **RStudio** console points to the folder where the active file is located (defined by  `setwd(dirname(rstudioapi::getActiveDocumentContext()$path))` in the code). With this structure, R scripts appear in the root of the working directory and data files are in a `'data/'` directory within the root, with **.shp** and **.tif** files located within the sub-folders `'data/shapes'` and `'data/rasters'` respectively. Following this recommendation simplifies the definition of paths and execution of the scripts. If users desire to change their storage paths, they have to properly adjust data paths in the R scripts.

