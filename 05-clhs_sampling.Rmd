
# Conditioned Latin Hypercube Sampling 

Conditioned Latin Hypercube Sampling (cLHS) is an advanced statistical method used for sampling multidimensional data developed within the context of digital Soil Mapping. It's an extension of the basic Latin Hypercube Sampling (LHS) technique, a statistical method for generating a distribution of samples of a random variable. The main advantage of LHS over simple random sampling is its ability to ensure that the entire range of the auxiliary variables are explored. It divides the range of each variable into intervals of equal probability and samples each interval.

The term 'conditioned' refers to the way the sampling is adapted or conditioned based on specific requirements or constraints. It often involves conditioning the sampling process on one or more additional variables or criteria. This helps in generating samples that are not just representative in terms of the range of values, but also in terms of their relationships or distributions. cLHS is particularly useful for sampling from multivariate data, where there are multiple interrelated variables as it occurs in soil surveys. The main advantage of cLHS is its efficiency in sampling and its ability to better capture the structure and relationships within the data, compared to simpler sampling methods, and ensures that the samples are representative not just of the range of each variable, but also of their interrelations. Detailed information on cLHS can be found in [@minasny2006].

In this manual, we use the R implementation of cLHS by [@Roudier2011] and available as an [R package](https://cran.r-project.org/web/packages/clhs/). Additionally, we also included the CLHS analyses using the package `'sgsR'`(https://cran.r-project.org/web/packages/sgsR/) from [@sgsR], since it provides options to include buffering distance constraints within the cLHS approach.


## cLHS Design

As for stratified sampling, the creation target points from a conditioned Latin Hypercube Sampling design involves the identification of the relevant features describing the environmental diversity in the area. In this case, the environmental parameters are incorporated in the form of raster covariates. The determination of the number of samples in the design is also required. This step can be calculated following the information already provided in this manual.

With the minimum sampling size of `r minimum_n` calculated before, we can conduct conditioned Latin Hypercube Sampling design for the area in the example using the R package `'cLHS'` available at CRAN. 

We use the rasters of `r paste(shQuote(names(cov.dat)), collapse = ", ")` as covariates in the exercise, which we convert to a raster.


```{r load_data_05, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}

  # Read Spatial data covariates as rasters with terra
  cov.dat <-  list.files(raster.path, pattern = "tif$",  recursive = TRUE, full.names = TRUE)
  cov.dat <- terra::rast(cov.dat) # SpatRaster from terra
  # Isolate factor raster, in this case layer 3 - geology
  r.factor <- cov.dat[[3]]  
  # Aggregate stack to simplify data rasters for calculations 
  # 1st aggregate quantitative layers
    cov.dat <- aggregate(cov.dat[[-3]], fact=agg.factor, fun="mean")
  # 2nd aggregate factor layers and add to stack  
    cov.dat$geology <- aggregate(r.factor, fact=agg.factor, fun="max") 
  # Create a raster::raster stack to be used as input in the clhs::clhs function 
    cov.dat.ras <- raster::stack(cov.dat) 

```


```{r fig-15, fig.cap="Covariates", eval=TRUE, include=TRUE}
  
# Plot of covariates
  plot(cov.dat)

```


The distribution of the sampling points is obtained using the `'cLHS'`function together with the stack of raster covariates and the minimum number of samples calculated in the previous Section. The function uses a number of iterations for the Metropolis-Hastings annealing process, with a default of 10000, to determine the optimal location of samples that account for a maximum of information on the raster covariates (Fig. \@ref(fig:fig-16). . 


```{r fig-16, fig.cap="Evolution of the objective function", eval=TRUE, include=TRUE}

  # Distribute sampling points with clhs
  pts <- clhs(cov.dat.ras, size = minimum_n, iter = 5000, progress = FALSE, simple = FALSE)
  # Plot of objective function
  plot(pts, c('obj'))

```



The distribution of points is shown in Figure \@ref(fig:fig-17).

```{r fig-17, fig.cap="Distribution of cLHS sampling points in the study area", eval=TRUE, include=TRUE}

  ## Create a cLHS sampling point set----
    plot(cov.dat[[1]], main="cLHS samples")
    points(pts$sampled_data, col="red", pch = 1)

```

## Including existing legacy data in a cHLS sampling design

In situations where there are legacy soil data samples available, it would be interesting to include them in the cLHS design to increase the diversity of covariates and avoid oversampling for some conditions. In this cases, the ancillary data can be included in the design as additional points to the `'clhs'` function.


```{r clhs-legacy-05, eval=TRUE, include=TRUE}

# We create an artificial legacy dataset of 20 samples over the study area
  legacy.data <- spatSample(cov.dat,20, na.rm=TRUE,xy=TRUE,method="random", as.points=T) # works with SpatRaster 

  # Get covariates data as a points
  cov.df<- as.points(cov.dat)
  
# Merge legacy and covariate information
  leg.new <-   rbind(legacy.data, cov.df)
  leg.new <- as.data.frame(leg.new,geom='XY')
  # Delete data from pixels outside the study area
  leg.new <- na.omit(leg.new)
  
# Calculate clhs 100 points plus locations of legacy data
    res <- clhs(x = leg.new, size = 100+length(legacy.data),  iter = 10000,simple = FALSE, progress = FALSE,
            must.include = c(1:nrow(legacy.data)))

# Get sampling points
  points <- res$sampled_data

```

Figure \@ref(fig:fig-18) shows the distribution of the created cLHS samples, which also include the position of the original legacy soil data points.

```{r fig-18, fig.cap="cLHS sampling points with legacy data", eval=TRUE, include=TRUE}

# Plot points
  plot(cov.dat[[1]], main="cLHS samples (blue circles) and legacy samples (red diamonds)")
  points(points[,c("x","y")], col="dodgerblue", pch = 1)
  points(legacy.data, col="red", pch = 5, cex=2)

```


## Working with large raster data

The cLHS function samples the covariates in the raster stack in order to determine the optimal location of samples that best represent the environmental conditions in the area. In the case of working with large raster sets, the process can be highly computing demanding since all pixels in the raster stack are used in the process. There are two simple methods to avoid this constraint:

 * **Aggregation of covariates:**  The quickest solution is to aggregate the covariates in the raster stack to a lower pixel resolution. This is directly performed using the `'aggregate'` function from the `'terra'`package. In case that the raster stack has discrete layers (factor data), the corresponding layers has to be aggregated separately using either the 'min' or 'max' functions to avoid corruption of the data and the results added later to the data of continuous raster layers. 

```{r aggregation-05, eval=FALSE, include=TRUE}

  ## Aggregation of raster stack by a factor of 2. 
  ## The original 10x10m grid resolution is resampled to 20x20m using the mean value of the pixels in the grid
    cov.dat <- aggregate(cov.dat, fact=2, fun="mean")

```


 * **Sampling covariate data:** Other method that can be used is to sample the stack (extract the covariates information at point scale)  on a regular grid at a lower resolution than the raster grid and use this information as input within the cLHS function. The creation of a regular point grid on the raster stack is straightforward through the function `spatSample` from the `'terra'` package. In this case we create a regular grid of 1000 points.

```{r fig-19, fig.cap="Low resolution points of covariate data", eval=TRUE, include=TRUE}

  # Create a regular grid of 1000 points on the covariate space
    regular.sample <- spatSample(cov.dat, size = 1000, xy=TRUE, method="regular", na.rm=TRUE)
  # plot the points over the 1st raster
    plot(cov.dat[[1]], main="Regular resampled data")
    points(regular.sample, col="red", pch = 1)

```

This `dataframe` can be directly used as input in the cLHS function to get locations that best represent the covariate space in the area.


```{r fig-20, fig.cap="cLHS sampling points on point-grid transformed raster covariate data", eval=TRUE, include=TRUE}

  # Create clhs samples upon the regular grid  
   regular.sample.clhs <- clhs(regular.sample, size = 100, progress = FALSE, iter = 10000, simple = FALSE)
  # Plot points of clhs samples
    points <- regular.sample.clhs$sampled_data # Get point coordinates of clhs sampling
    plot(cov.dat[[1]], main="cLHS samples (red) and covariated resampled points (blue)")
    points(regular.sample, col="dodgerblue", pch = 1)
    points(points, col="red", cex=1)

```

Note that the sampling design follows the regular pattern of the regular grid extracted from the raster covariates 


## Implemenentation of cost-constrained sampling

There are situation in which the accessibility to some locations is totally or partially restricted such as areas with steep slopes, remote areas, or areas with forbidden access, which highly compromises the sampling process. For these cases, the sampling design can constrain the points to particular locations by defining environmental layers that cause an increment in the cost efficiency of the sampling. This is done with the `cost` attribute in the main `'clhs'` function. The following example uses the raster layer "distance to roads" as a cost layer to avoid low accessible points located at large distance from roads while optimizing the representativeness of the remaining environmental covariates.

```{r fig-21, fig.cap="Objective and cost funtions", eval=TRUE, include=TRUE, warning=FALSE}
  # Create a cLHS sampling point set with 
  cost.clhs <- clhs(cov.dat.ras, size = minimum_n, iter = 5000, progress = FALSE, simple = FALSE, cost = 'cost',  use.cpp = T)
  # Plot objective function
  plot(pts, c('obj', 'cost'))

```


Figure \@ref(fig:fig-22) shows the distribution of the cost constrained `'clhs'` sampling over the `'cost'` surface. The sampling procedure concentrates, as much as possible, sampling sites in locations with lower costs.


```{r fig-22, fig.cap="cLHS sampling with cost layers", eval=TRUE, include=TRUE, warning=F}
  # Get and plot the point of samples
  points <- cost.clhs$sampled_data  # Get point coordinates of clhs sampling
  plot(cov.dat[[2]], main="cLHS samples with 'cost' constraints")
  points(points, col="red", cex=1)
  
```


Cost surfaces can be defined by other parameters than distances to roads. They can represent private property boundaries, slopes, presence of wetlands, etc. The  package `'sgsR'` implements functions to define both cost surfaces and distances to roads simultaneously. In this case, it is possible to define an inner buffer distance (i.e. the distance from the roads that should be avoided for sampling) and an outer buffer - i.e. the maximum sampling distance) from roads to maximise the variability of the sampling point while considering these limits. The `'sample_clhs'` function in this package also includes options to include existing legacy data in the process of clhs sampling. 


```{r sample_clhs, eval=TRUE, include=TRUE, warning=FALSE, message=FALSE}

# Load, roads and legacy data 
  roads <- sf::st_read(file.path(paste0(shp.path,"/road.shp")),quiet=TRUE)
  legacy <- sf::st_read(file.path(paste0(shp.path,"/legacy_soils.shp")),quiet=TRUE)
# Calculate distance to roads 
  cost <- calculate_distance(raster = cov.dat, access = roads)
# Eliminate the data from common NA values in the area
  cost$dist2access<-cost$dist2access*cost$claymin/cost$claymin
# Calculate clhs points with legacy, cost and buffer to roads
  buff_inner=20;
  buff_outer=300
  aa <- sample_clhs( mraster = cost, nSamp = 300, existing = legacy, iter = 250, details = TRUE, cost="cost", access=roads, buff_inner=buff_inner, buff_outer=buff_outer)

```


```{r fig-22b, fig.cap="cLHS sampling with legacy data, cost surface and distance buffers around roads", eval=TRUE, include=TRUE, message=FALSE, warning = FALSE}

## Plot distances, roads, clhs points and legacy data 
  plot(cost$dist2access)
  plot(roads,add=TRUE)
  plot(aa$samples[aa$samples$type=="new",], col= "tomato",add=TRUE)
  plot(aa$samples[aa$samples$type=="existing",], col= "navy",add=TRUE)

```


Legacy data is represented as blue dots while new samples from cLHS analyses are in red color (Fig.\@ref(fig:fig-22)). Note that the new sampling points are located within a distance buffer of `r buff_inner`-`r buff_outer` meters from roads. In addition, a cost surface has also been included in the analyses.


## Replacement areas in cLHS design

The `'cLHS'` package incorporates methods for the delineation of replacement locations that could be utilized in the case any sampling point is unreachable. In this case, the function determines the probability of similarity to each point in an area determined by a buffer distance around the points. 

```{r cLHS_buffer_05, eval=TRUE, include=TRUE}

  ## Determine the similarity to points in a buffer of distance D
  # Compute the buffers around points  
    gw <- similarity_buffer(cov.dat.ras, pts$sampled_data, buffer = D)

```

The similarity probabilities for the first cLHS point is presented on Figure \@ref(fig:fig-23) over the elevation layer. 

```{r fig-23, fig.cap="Probability of similarity in the buffer for the first cLHS point (in black) over elevation. The blue crosses represent the location of the remaining cLHS points from the analysis.", eval=TRUE, include=TRUE}

  # Plot elevation
    plot(cov.dat[[3]], legend=TRUE,main=paste("Similarity Probability over elevation"))
  ## Overlay points
    points(pts$sampled_data[1], col = "dodgerblue", pch = 3)
  ## Overlay probability stack for point 1
    colors <- c((RColorBrewer::brewer.pal(9, "YlOrRd")))
    terra::plot(gw[[1]], add=TRUE ,  legend=FALSE, col=colors)
  ## Overlay 1st cLHS point
    points(pts$sampled_data[1,1], col = "black", pch = 3,cex=1)

```

The probabilities can then be reclassified using a threshold value to delineate the areas with higher similarity to each central target point. 

```{r cLHS_reclass_05, eval=TRUE, include=TRUE, warning=FALSE}
  # Determine the threshold break to determine if the surrounding area can be a replacement or not
    similarity_threshold <- 0.90
  # Reclassify buffer raster data according to the threshold break of probability
  # 1 = similarity >= similarity_break; NA =  similarity <  similarity_break
    # Define a vector with the break intervals and the output values (NA,1) 
    breaks <- c(0, similarity_threshold, NA, similarity_threshold, 1, 1)
    # Convert to a matrix
    breaks <- matrix(breaks, ncol=3, byrow=TRUE)
    # Reclassify the data in the layers from probabilities to (NA,)
    s = stack(lapply(1:raster::nlayers(gw), function(i){raster::reclassify(gw[[i]], breaks, right=FALSE)}))

```


The reclassified raster stack is then converted to an object of `'SpatialPolygonsDataFrame'` class.

```{r cLHS_polygonize_05, eval=TRUE, include=TRUE}

   ## Polygonize replacement areas 
    s = lapply(as.list(s), rasterToPolygons, dissolve=TRUE)
    s <- bind(s,keepnames=TRUE)
    
    # Add the identifier of the corresponding target point
    for(i in 1: length(s)){
      s@data$ID[i] <- as.integer(stringr::str_replace(s@polygons[[i]]@ID,"1.",""))
    }
    # Clean the data by storing target ID data only
    s@data <- s@data["ID"]

```


The results are shown in Figure \@ref(fig:fig-24).

```{r fig-24, fig.cap="Distribution of cLHS sampling points in the study area", eval=TRUE, include=TRUE}

    plot(cov.dat[[1]], main=paste("cLHS samples and replacement areas for threshold = ", similarity_threshold))
    plot(s,add=TRUE, col=NA, border="gray40")
    points(pts$sampled_data, col="red", pch = 3)

```


The layer of replacement areas can finally be exported to a `'shapefile'` to be used in any other software.

```{r cLHS_export_05, eval=FALSE, include=TRUE, warning=FALSE, results='hide'}
    
   # Write replacement areas to polygon shape 
    s <- st_as_sf(s)
    st_write(s, file.path(paste0(results.path,'replacement_areas_', D, '.shp')), delete_dsn = TRUE)
  # Write cLHS sampling points to shapefile
    out.pts <- st_as_sf(pts$sampled_data)
    st_write(out.pts, paste0(results.path,'target_clhs.shp'), delete_dsn = TRUE)
    

```

